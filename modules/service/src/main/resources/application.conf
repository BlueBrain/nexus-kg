include "app.conf"
include "cassandra.conf"
include "sparql.conf"
include "kamon.conf"

akka {
  http.server.parsing.max-content-length = 10g

  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
  log-dead-letters = off
  loglevel = INFO
  loglevel = ${?LOG_LEVEL}

  extensions += "akka.cluster.ddata.DistributedData"

  actor {
    provider = "akka.cluster.ClusterActorRefProvider"

    serializers {
      circeEvent = "ch.epfl.bluebrain.nexus.kg.service.io.Serializer$EventSerializer"
    }

    serialization-bindings {
      "ch.epfl.bluebrain.nexus.kg.core.domains.DomainEvent"     = circeEvent
      "ch.epfl.bluebrain.nexus.kg.core.organizations.OrgEvent"  = circeEvent
      "ch.epfl.bluebrain.nexus.kg.core.schemas.SchemaEvent"     = circeEvent
      "ch.epfl.bluebrain.nexus.kg.core.contexts.ContextEvent"   = circeEvent
      "ch.epfl.bluebrain.nexus.kg.core.instances.InstanceEvent" = circeEvent
    }
  }

  cluster {
    min-nr-of-members = 1
    sharding.state-store-mode = ddata
  }

  remote {
    enabled-transports = ["akka.remote.netty.tcp"]
    netty.tcp {
      hostname = ${app.instance.interface}
      hostname = ${?REMOTING_INTERFACE}
      hostname = ${?override.remoting.interface}
      port = 2552
      port = ${?REMOTING_PORT}
      port = ${?override.remoting.port}
    }
  }

  persistence {
    journal.plugin = ${app.persistence.journal.plugin}
    snapshot-store.plugin = ${app.persistence.snapshot-store.plugin}
  }
}
